// üéØ CORRE√á√ÉO ESPEC√çFICA PARA PROCESSAMENTO DE IMAGEM
// Baseado no bot que funciona corretamente

// 1. SUBSTITUIR A FUN√á√ÉO processImage por esta vers√£o:

async function processImage(imagePath, caption = '') {
    try {
        logger.logMedia('üñºÔ∏è INICIANDO PROCESSAMENTO DE IMAGEM', '', 'image', {
            path: imagePath,
            caption: caption,
            file_exists: fs.existsSync(imagePath)
        });

        if (!fs.existsSync(imagePath)) {
            throw new Error(`Arquivo de imagem n√£o encontrado: ${imagePath}`);
        }

        const imageBuffer = fs.readFileSync(imagePath);
        logger.logMedia('üìÅ ARQUIVO LIDO COM SUCESSO', '', 'image', {
            buffer_size: imageBuffer.length,
            buffer_type: typeof imageBuffer
        });

        const base64Image = imageBuffer.toString('base64');
        logger.logMedia('üîÑ CONVERS√ÉO BASE64 CONCLU√çDA', '', 'image', {
            base64_length: base64Image.length,
            base64_preview: base64Image.substring(0, 50) + '...'
        });

        const prompt = caption ? 
            `Analise esta imagem. Contexto adicional: ${caption}` :
            "Analise esta imagem e descreva o que voc√™ v√™ de forma detalhada.";

        logger.logMedia('ü§ñ ENVIANDO PARA GPT-4O', '', 'image', {
            prompt: prompt,
            model: 'gpt-4o',
            max_tokens: 500
        });

        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: prompt
                        },
                        {
                            type: "image_url",
                            image_url: {
                                url: `data:image/jpeg;base64,${base64Image}`
                            }
                        }
                    ]
                }
            ],
            max_tokens: 500
        });

        const analysis = response.choices[0].message.content;
        logger.logMedia('‚úÖ AN√ÅLISE DE IMAGEM CONCLU√çDA', '', 'image', {
            analysis_length: analysis.length,
            response_preview: analysis.substring(0, 100) + '...'
        });

        // Limpar arquivo tempor√°rio
        try {
            fs.unlinkSync(imagePath);
            logger.logMedia('üóëÔ∏è ARQUIVO TEMPOR√ÅRIO REMOVIDO', '', 'image', { path: imagePath });
        } catch (cleanupError) {
            logger.logError('Erro ao remover arquivo tempor√°rio', cleanupError, { path: imagePath });
        }

        // üéØ DIFEREN√áA PRINCIPAL: Retorna apenas a an√°lise, sem formata√ß√£o extra
        return analysis; // ‚Üê SEM "üñºÔ∏è *An√°lise da imagem:*\n\n"
    } catch (error) {
        logger.logError('‚ùå ERRO NO PROCESSAMENTO DE IMAGEM', error, { path: imagePath });
        
        // Tentar limpar arquivo em caso de erro
        try {
            if (fs.existsSync(imagePath)) {
                fs.unlinkSync(imagePath);
            }
        } catch (cleanupError) {
            logger.logError('Erro ao limpar arquivo ap√≥s falha', cleanupError);
        }
        
        return "‚ùå Desculpe, n√£o consegui processar esta imagem. Tente enviar novamente.";
    }
}

// 2. SUBSTITUIR O TRECHO DE PROCESSAMENTO DE IMAGEM NO EVENT LISTENER por:

} else if (message.message.imageMessage) {
    // Mensagem de imagem
    logger.logMedia('üñºÔ∏è IMAGEM DETECTADA', from, 'image');
    
    try {
        logger.logMedia('üì• INICIANDO DOWNLOAD DA IMAGEM', from, 'image');
        
        const buffer = await downloadMediaMessage(message, 'buffer', {});
        
        if (!buffer || buffer.length === 0) {
            throw new Error('Buffer de imagem vazio');
        }
        
        logger.logMedia('‚úÖ DOWNLOAD DA IMAGEM CONCLU√çDO', from, 'image', {
            buffer_size: buffer.length
        });
        
        // üéØ DIFEREN√áA: Nome do arquivo mais simples
        const imagePath = path.join(MEDIA_DIR, `image_${Date.now()}.jpg`);
        fs.writeFileSync(imagePath, buffer);
        
        logger.logMedia('üíæ IMAGEM SALVA TEMPORARIAMENTE', from, 'image', {
            path: imagePath,
            file_exists: fs.existsSync(imagePath)
        });
        
        const caption = message.message.imageMessage.caption || '';
        const imageAnalysis = await processImage(imagePath, caption);
        
        // üéØ DIFEREN√áA PRINCIPAL: Cria um prompt contextualizado para o assistente
        const prompt = `Baseado na an√°lise da imagem a seguir, forne√ßa uma resposta √∫til e contextualizada para o usu√°rio:

An√°lise da imagem: ${imageAnalysis}

Mensagem do usu√°rio: ${caption || 'Usu√°rio enviou uma imagem'}

Forne√ßa uma resposta natural e √∫til baseada no conte√∫do da imagem.`;

        // üéØ ENVIA O PROMPT CONTEXTUALIZADO PARA O ASSISTENTE (n√£o a an√°lise direta)
        await messageQueue.addMessage(from, {
            type: 'image',
            content: prompt // ‚Üê Envia o prompt contextualizado, n√£o a an√°lise bruta
        });
        
        logger.logMedia('üéØ PROCESSAMENTO DE IMAGEM FINALIZADO', from, 'image', {
            prompt_length: prompt.length
        });
        
    } catch (imageError) {
        logger.logError('‚ùå ERRO NO PROCESSAMENTO DE IMAGEM', imageError, {
            from: from
        });
        
        await messageQueue.addMessage(from, {
            type: 'image',
            content: "‚ùå Desculpe, n√£o consegui processar esta imagem. Tente enviar novamente."
        });
    }

/*
üéØ EXPLICA√á√ÉO DA DIFEREN√áA PRINCIPAL:

BOT ATUAL (problem√°tico):
1. Usu√°rio envia imagem
2. GPT-4 Vision analisa ‚Üí "Esta √© uma pe√ßa t√©cnica..."
3. Adiciona √† fila como: "üñºÔ∏è *An√°lise da imagem:* Esta √© uma pe√ßa t√©cnica..."
4. Assistant processa e responde: "Agrade√ßo a descri√ß√£o detalhada!"

BOT CORRETO (funcionando):
1. Usu√°rio envia imagem  
2. GPT-4 Vision analisa ‚Üí "Esta √© uma pe√ßa t√©cnica..."
3. Cria prompt contextualizado: "Baseado na an√°lise da imagem a seguir, forne√ßa uma resposta √∫til..."
4. Assistant processa o prompt contextualizado e responde adequadamente

A DIFEREN√áA √â QUE O BOT CORRETO:
- Remove a formata√ß√£o "üñºÔ∏è *An√°lise da imagem:*"
- Cria um prompt que instrui o assistant sobre como usar a an√°lise
- O assistant entende que deve responder baseado na an√°lise, n√£o agradecer por ela
*/

